{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DataCamp Data Science Courses**\n",
    "# **Extreme Gradient Boosting with XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap 1: Classification with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to the course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning\n",
    "- Regression: covered in chapter 2\n",
    "- Classification\n",
    "    - binary: predict a person will buy insurance\n",
    "        - metric: AUC (Area under the ROC Curve)\n",
    "    - multi-class: classifying the species of a given bird in an image\n",
    "        - metric: accuracy score, confusion matrix\n",
    "\n",
    "common classification models: logistic regression, decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning considerations  \n",
    "- Features can be either numeric or categorical\n",
    "- Numeric features should be scaled (Z-scored)\n",
    "    - e.g. essential to train SVM models\n",
    "- Categorical features should be encoded (one-hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other kinds of Supervised Learning problems\n",
    "- Ranking: Predicting an ordering on a set of choices\n",
    "    - Google search suggestions\n",
    "- Recommendation: Recommending an item to a user based on his/her consumption history and profile\n",
    "    - Netflix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optimized gradient-boosting machine learning library  \n",
    "- Originally written in C++  \n",
    "- Why it is popular  \n",
    "    - Speed and performance\n",
    "    - Core algorithm is parallelizable\n",
    "    - Consistently outperforms single-algorithm methods\n",
    "    - State-of-the-art performance in many ML benchmark datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'datasets/classification_data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f105d356d9a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Using XGBoost: A Quick Example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclass_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"datasets/classification_data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'datasets/classification_data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Using XGBoost: A Quick Example\n",
    "\n",
    "class_data = pd.read_csv(\"datasets/classification_data.csv\")\n",
    "\n",
    "X, y = class_data.iloc[:,:-1], class_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y,test_size=0.2, random_state=123)\n",
    "\n",
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic',n_estimators=10, seed=123)\n",
    "\n",
    "xg_cl.fit(X_train, y_train)\n",
    "preds = xg_cl.predict(X_test)\n",
    "\n",
    "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
    "print(\"accuracy: %f\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'churn_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8f1af86ca7e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Create arrays for the features and the target: X, y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchurn_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchurn_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Create the training and test sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'churn_data' is not defined"
     ]
    }
   ],
   "source": [
    "# XGBoost: Fit/Predict\n",
    "\n",
    "# Import xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create arrays for the features and the target: X, y\n",
    "X, y = churn_data.iloc[:,:-1], churn_data.iloc[:,-1]\n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Instantiate the XGBClassifier: xg_cl\n",
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=123)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "xg_cl.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_cl.predict(X_test)\n",
    "\n",
    "# Compute the accuracy: accuracy\n",
    "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
    "print(\"accuracy: %f\" % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a decision tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees  \n",
    "- Base learner - Individual learning algorithm in an ensemble algorithm\n",
    "- Composed of a series of binary questions\n",
    "- Predictions happen at the \"leaves\" of the tree\n",
    "    - leaf nodes always contain decision values\n",
    "- Constructed iteratively (one decision at a time)\n",
    "    - Until a stopping criterion is met\n",
    "- Individual decision trees tend to overfit\n",
    "    - low bias, high variance\n",
    "    - tend to overfit training data, and generalize poorly to new data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost\n",
    "- Uses classification and regression trees (CART)\n",
    "- Contain real-valued score in each leaf\n",
    "    - regardless of classification or regression problem\n",
    "    - can be thresholded to convert into categories for classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision trees\n",
    "\n",
    "# Import the necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import datasets\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X = bc.data\n",
    "y = bc.target\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Instantiate the classifier: dt_clf_4\n",
    "dt_clf_4 = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "dt_clf_4.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred_4\n",
    "y_pred_4 = dt_clf_4.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the predictions: accuracy\n",
    "accuracy = float(np.sum(y_pred_4==y_test))/y_test.shape[0]\n",
    "print(\"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting overview\n",
    "- Not a specific machine learning algorithm\n",
    "- Concept that can be applied to a set of machine learning models\n",
    "    - \"Meta-algorithm\"\n",
    "- Ensemble meta-algorithm used to convert many weak learners into a strong learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Weak learner: ML algorithm that is slightly better than chance\n",
    "    - Example: Decision tree whose predictions are slightly better than 50%\n",
    "- Boosting converts a collection of weak learners into a strong learner\n",
    "- Strong learner: Any algorithm that can be tuned to achieve good performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How boosting is accomplished\n",
    "- Iteratively learning a set of weak models on subsets of the data\n",
    "- Weighing each weak prediction according to each weak learner's performance\n",
    "- Combine the weighted predictions to obtain a single weighted prediction that is much better than the individual predictions themselves!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation through cross-validation  \n",
    "- Cross-validation: Robust method for estimating the performance of a model on unseen data\n",
    "- Generates many non-overlapping train/test splits on training data\n",
    "- Reports the average test set performance across all data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'classification_data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-20357185e733>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Cross-validation in XGBoost example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclass_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"classification_data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m churn_dmatrix = xgb.DMatrix(data=churn_data.iloc[:,:-1],\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'classification_data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Cross-validation in XGBoost example\n",
    "\n",
    "class_data = pd.read_csv(\"classification_data.csv\")\n",
    "\n",
    "churn_dmatrix = xgb.DMatrix(data=churn_data.iloc[:,:-1],\n",
    "                            label=churn_data.month_5_still_here)\n",
    "\n",
    "params={\"objective\":\"binary:logistic\",\"max_depth\":4}\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=4,\n",
    "                    num_boost_round=10, metrics=\"error\", as_pandas=True)\n",
    "\n",
    "print(\"Accuracy: %f\" %((1-cv_results[\"test-error-mean\"]).iloc[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_boost_round: number of trees to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test-error-mean  test-error-std  train-error-mean  train-error-std\n",
      "0         0.066824        0.019564          0.025480         0.002451\n",
      "1         0.061524        0.013876          0.021969         0.001257\n",
      "2         0.056252        0.010004          0.014945         0.006589\n",
      "3         0.052734        0.011418          0.012306         0.003300\n",
      "4         0.054497        0.012485          0.010549         0.004314\n",
      "0.945502666667\n"
     ]
    }
   ],
   "source": [
    "# Measuring accuracy\n",
    "\n",
    "# Create the DMatrix: churn_dmatrix\n",
    "churn_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:logistic\", \"max_depth\":3}\n",
    "\n",
    "# Perform cross-validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=3, num_boost_round=5, metrics=\"error\", as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Print the accuracy\n",
    "print(((1-cv_results[\"test-error-mean\"]).iloc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
      "0       0.961473      0.024760        0.987225       0.001301\n",
      "1       0.969078      0.022616        0.993244       0.004295\n",
      "2       0.972491      0.024377        0.995224       0.003751\n",
      "3       0.971354      0.025405        0.997125       0.002042\n",
      "4       0.974002      0.026527        0.997610       0.001871\n",
      "0.974002\n"
     ]
    }
   ],
   "source": [
    "# Measuring AUC\n",
    "\n",
    "# Perform cross_validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=3, num_boost_round=5, metrics=\"auc\", as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Print the AUC\n",
    "print((cv_results[\"test-auc-mean\"]).iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When should I use XGBoost?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When to use XGBoost\n",
    "- You have a large number of training samples\n",
    "    - Greater than 1000 training samples and less 100 features\n",
    "    - The number of features < number of training samples\n",
    "- You have a mixture of categorical and numeric features\n",
    "    - Or just numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When NOT to use XGBoost\n",
    "- Image recognition\n",
    "- Computer vision\n",
    "- Natural language processing and understanding problems\n",
    "- When the number of training samples is significantly smaller than the number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap 2: Regression with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common regression metrics\n",
    "- Root mean squared error (RMSE)\n",
    "    - Treats negative and positive differences equally\n",
    "    - Tends to punish larger differences more than smaller ones\n",
    "- Mean absolute error (MAE)\n",
    "    - Not affected by large error values as RMSE\n",
    "    - Lacks nice mathematical properties\n",
    "    - Less frequently used as evaluation metric\n",
    "\n",
    "Common regression algorithms\n",
    "- Linear regression\n",
    "- Decision trees\n",
    "    - Can be used for both regression/classification tasks\n",
    "    - Important building block for XGBoost models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective (loss) functions and base learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss/Objective Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quantifies how far off a prediction is from the actual result  \n",
    "- Measures the difference between estimated and true values for some collection of data  \n",
    "- **Goal**: Find the model that yields the minimum value of the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loss function names in xgboost:\n",
    "    - **reg:linear** - use for regression problems\n",
    "    - **reg:logistic** - use for classification problems when you want just decision, not probability\n",
    "    - **binary:logistic** - use when you want probability rather than just decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost involves creating a meta-model that is composed of many individual models that combine to give a final prediction\n",
    "- Individual models = base learners\n",
    "    - Want base learners that are slightly better than random guessing for some part of data but are uniformly bad for the remaining majority of the data.\n",
    "    - When combined they create final prediction that is **non-linear**\n",
    "    - Each base learner should be good at distinguishing or predicting different parts of the dataset\n",
    "- Two kinds of base learners: **tree** and **linear**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREES BASE LEARNERS example: Scikit-learn API\n",
    "\n",
    "boston_data = pd.read_csv(\"datasets/boston.csv\")\n",
    "X, y = boston_data.iloc[:,:-1],boston_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective='reg:linear',n_estimators=10, seed=123)\n",
    "\n",
    "xg_reg.fit(X_train, y_train)\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 9.749041\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test,preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR BASE LEARNERS Example: Learning API Only\n",
    "\n",
    "boston_data = pd.read_csv(\"datasets/boston.csv\")\n",
    "X, y = boston_data.iloc[:,:-1],boston_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "DM_train = xgb.DMatrix(data=X_train,label=y_train)\n",
    "DM_test = xgb.DMatrix(data=X_test,label=y_test)\n",
    "\n",
    "# OPTIONS FOR BOOSTER: gbtree(default), gblinear or dart\n",
    "params = {\"booster\":\"gblinear\",\"objective\":\"reg:linear\"}\n",
    "\n",
    "xg_reg = xgb.train(params = params, dtrain=DM_train,num_boost_round=10)\n",
    "preds = xg_reg.predict(DM_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5.492696\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test,preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EXERCISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 56), (1460,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision trees as base learners\n",
    "\n",
    "df = pd.read_csv('datasets/ames_housing_trimmed_processed.csv')\n",
    "X, y = df.iloc[:,:-1],df.iloc[:,-1]\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 78847.401758\n"
     ]
    }
   ],
   "source": [
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Instantiate the XGBRegressor: xg_reg\n",
    "xg_reg = xgb.XGBRegressor(objective='reg:linear',n_estimators=10)\n",
    "\n",
    "# Fit the regressor to the training set\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "# Compute the rmse: rmse\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 43566.535658\n"
     ]
    }
   ],
   "source": [
    "# Linear base learners\n",
    "\n",
    "# Convert the training and testing sets into DMatrixes: DM_train, DM_test\n",
    "DM_train = xgb.DMatrix(data=X_train,label=y_train)\n",
    "DM_test =  xgb.DMatrix(data=X_test,label=y_test)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"booster\":\"gblinear\", \"objective\":\"reg:linear\"}\n",
    "\n",
    "# Train the model: xg_reg\n",
    "xg_reg = xgb.train(dtrain= DM_train, params=params, num_boost_round=5)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_reg.predict(DM_test)\n",
    "\n",
    "# Compute and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test,preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test-rmse-mean  test-rmse-std  train-rmse-mean  train-rmse-std\n",
      "0   142980.433594    1193.791602    141767.531250      429.454591\n",
      "1   104891.394532    1223.158855    102832.544922      322.469930\n",
      "2    79478.937500    1601.344539     75872.615235      266.475960\n",
      "3    62411.920899    2220.150028     57245.652344      273.625086\n",
      "4    51348.279297    2963.377719     44401.298828      316.423666\n",
      "4    51348.279297\n",
      "Name: test-rmse-mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Evaluating model quality\n",
    "\n",
    "# RMSE Model\n",
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
    "\n",
    "# Perform cross-validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=4, num_boost_round=5, metrics='rmse', as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Extract and print final boosting round metric\n",
    "print((cv_results[\"test-rmse-mean\"]).tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test-mae-mean  test-mae-std  train-mae-mean  train-mae-std\n",
      "0  127634.000000   2404.009898   127343.482422     668.308109\n",
      "1   90122.501954   2107.912810    89770.056641     456.965267\n",
      "2   64278.558594   1887.567576    63580.791016     263.404950\n",
      "3   46819.168946   1459.818607    45633.155274     151.883420\n",
      "4   35670.646485   1140.607452    33587.090820      86.999396\n",
      "4    35670.646485\n",
      "Name: test-mae-mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
    "\n",
    "# Perform cross-validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=4, num_boost_round=5, metrics='mae', as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Extract and print final boosting round metric\n",
    "print((cv_results[\"test-mae-mean\"]).tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization and base learners in XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regularization is a control on model complexity\n",
    "- Want models that are both accurate and as simple as possible\n",
    "- Tweak parameters to limit model complexity by altering loss function\n",
    "- Regularization parameters in XGBoost:\n",
    "    - gamma \n",
    "        - for tree base learners\n",
    "        - controls whether a node on base learner split based on the expected reduction in the loss that would occur after performing the split\n",
    "        - higher values lead to fewer splits\n",
    "        - minimum loss reduction allowed for a split to occur\n",
    "    - alpha \n",
    "        - another name for l1 regularization \n",
    "        - penalty on leaf weights rather than feature weights, as is the case in linear or logistic regression\n",
    "        - higher alpha values mean more regularization, causes many leaf weights in the base learners to be 0\n",
    "    - lambda \n",
    "        - another name for l2 regularization\n",
    "        - much smoother penalty than l1\n",
    "        - causes leaf weights to smoothly decrease instead of enforcing strong sparsity constraints on the leaf weights as in l1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 Regularization in XGBoost example\n",
    "\n",
    "boston_data = pd.read_csv(\"datasets/boston.csv\")\n",
    "X,y = boston_data.iloc[:,:-1],boston_data.iloc[:,-1]\n",
    "\n",
    "boston_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "params={\"objective\":\"reg:linear\",\"max_depth\":4}\n",
    "\n",
    "l1_params = [1,10,100]\n",
    "rmses_l1=[]\n",
    "\n",
    "for reg in l1_params:\n",
    "    params[\"alpha\"] = reg\n",
    "    cv_results = xgb.cv(dtrain=boston_dmatrix, params=params,\n",
    "                        nfold=4, num_boost_round=10,\n",
    "                        metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    rmses_l1.append(cv_results[\"test-rmse-mean\"] \\\n",
    "                    .tail(1).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best rmse as a function of l1:\n",
      "    l1      rmse\n",
      "0    1  3.461474\n",
      "1   10  3.821152\n",
      "2  100  4.645519\n"
     ]
    }
   ],
   "source": [
    "print(\"Best rmse as a function of l1:\")\n",
    "print(pd.DataFrame(list(zip(l1_params,rmses_l1)),columns=[\"l1\",\"rmse\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base learners in XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Base Learner:\n",
    "    - Sum of linear terms (same as in linear/logistic regression models)\n",
    "    - When combined into an ensemble, the boosted model is weighted sum of linear models (thus is itself linear)\n",
    "    - Don't get any nonlinear combination of features in the final model\n",
    "    - Rarely used\n",
    "- Tree Base Learner:\n",
    "    - Decision trees as base model\n",
    "    - When combined into an ensemble, boosted model is weighted sum of decision trees (nonlinear)\n",
    "    - Almost exclusively used in XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best rmse as a function of l2:\n",
      "    l2       rmse\n",
      "0    1   6.022222\n",
      "1   10   7.201520\n",
      "2  100  10.692151\n"
     ]
    }
   ],
   "source": [
    "# Using L2 regularization in XGBoost\n",
    "\n",
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "reg_params = [1, 10, 100]\n",
    "\n",
    "# Create the initial parameter dictionary for varying l2 strength: params\n",
    "params = {\"objective\":\"reg:linear\",\"max_depth\":3}\n",
    "\n",
    "# Create an empty list for storing rmses as a function of l2 complexity\n",
    "rmses_l2 = []\n",
    "\n",
    "# Iterate over reg_params\n",
    "for reg in reg_params:\n",
    "\n",
    "    # Update l2 strength\n",
    "    params[\"lambda\"] = reg\n",
    "    \n",
    "    # Pass this updated param dictionary into cv\n",
    "    cv_results_rmse = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2, num_boost_round=5, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append best rmse (final round) to rmses_l2\n",
    "    rmses_l2.append(cv_results_rmse[\"test-rmse-mean\"].tail(1).values[0])\n",
    "\n",
    "# Look at best rmse per l2 param\n",
    "print(\"Best rmse as a function of l2:\")\n",
    "print(pd.DataFrame(list(zip(reg_params, rmses_l2)), columns=[\"l2\", \"rmse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAD8CAYAAAB6iWHJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27cb6d5dcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing individual XGBoost trees\n",
    "\n",
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":2}\n",
    "\n",
    "# Train the model: xg_reg\n",
    "xg_reg = xgb.train(params=params, dtrain=housing_dmatrix, num_boost_round=10)\n",
    "\n",
    "# Plot the first tree\n",
    "xgb.plot_tree(xg_reg, num_trees=0)\n",
    "plt.rcParams[\"figure.figsize\"] = [7,7]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAF9CAYAAABhze19AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncmosZERE5NT+H/bIWsB8DyC9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27cb6aef3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the fifth tree\n",
    "xgb.plot_tree(xg_reg, num_trees=4)\n",
    "plt.rcParams[\"figure.figsize\"] = [7,7]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAADRCAYAAACpZDdcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl4U2XaP/DvaQuUtVRoRZGyWkQo\nMIJaWd4BXNBhUhArFKHIIPxsUeSdgVGcNx1UZBHKDCKCtDo6gLYUEUhRQWnLINoyRe0iW2VLYZSk\nCAlg2drevz/OnJCkSZqmSZ4s9+e6cjXJOec536Rt7jxneY5ERATGGGPMT4WIDsAYY4w1BRcyxhhj\nfo0LGWOMMb/GhYwxxphf40LGGGPMr3EhY4wx5te4kDHGGPNrXMgYY4z5NS5kjDHG/BoXMsYYY36N\nCxljjDG/FiY6AGPMUl1dHfbv34+KigpUVFTg3LlzqK6uBhGhdevW6NixI2JjYxEbG4v7778fISH8\nfZQFN4kHDWZMjBs3buDtt9/GypUrodVqMWrUKIwaNQrdu3fH8OHD0aVLF4fLnz59Gvv27UNBQQG2\nbduGqqoqJCYmYt68ebj//vu99CoYE48LGWNetGPHDqSmpiIsLAwLFy7ElClT3L6OyspKLF68GOvW\nrcOMGTOwevVqtGjRwu3rYcxXcCFjzMOOHTuGoUOH4q677sKmTZvQqVMnr65/zZo1mD17NubNm4c3\n3njDq+tmzBu4kDHmIStXrsS8efOwY8cOPProo6LjoK6uDhMnTkRxcTHKy8vRtm1b0ZEYcwsuZIy5\n2YIFC7B27VpUVFSgffv2ouPY9MYbb2DRokWorKz02YyMOYsLGWNusnXrVkydOhVnzpxBRESE6DhO\neeWVV7Bx40YcO3ZMdBTGXMaFjLEmunbtGtq2bYu9e/ciPj5edByXxMfH4+GHH8bChQtFR2Gs0fg8\nMsaa4M9//jMOHjyI69evi47SJEVFRaisrERoaCj+9Kc/Yfny5aIjMeY0LmSMuahVq1b44Ycf0KNH\nD9FR3CImJga1tbU4ceIEWrVqherqatGRGHMKDwnAWCOdPHkSHTt2RHV1dcAUMXM9evRAdXU1Onbs\niJMnT4qOw1iDuEfGWCNs3LgRu3btwrlz50RH8bhz584hOTkZo0eP9siJ2+ymCRMmiI4gXE5OjsvL\n8sEejDkpJSUF8fHxmDZtmugoXvXBBx+gsLAQ69atEx0lYPXv3x9lZWWiYwjT1NfPmxYZc0JiYiKm\nTJkSdEUMAKZNm4apU6di/PjxoqMwZhNvWmSsAUlJSUhLS8OAAQNERxFm6NChaNeuHSZOnIhNmzaJ\njsOYBe6RMebA7NmzMXv27KAuYoq4uDjMmTMHs2fPFh2FMQtcyBizQ6PRID4+HkOHDhUdxWcMGTIE\n8fHx0Gg0oqMwZsKFjDEbqqqqkJOTg8mTJ4uO4nMmT56MnJwcVFVViY7CGADeR8aYTX379oVerxcd\nw2dt3LgR0dHR/B4xn8A9MsasdOrUiT+gnaDX671+bTXGbOFCxpiZt99+G/v37xcdw2/s378fq1ev\nFh0jYKWmpkKSJKfmzc/PR2VlJbKzs+3Ok5CQgNzc3HrPS5JkuinLG41GZGZmWsxXWloKSZKQmpoK\nQP4yY74MAOTm5tZ7TmnbU/iEaMb+67HHHkOLFi2wbds20VH8yuOPP46tW7eKjuHXHJ0QLEkSnPmY\nbmg+ZXppaSkAWByJW1lZiZiYGOj1ekRHR9ttMzc3FyqVyuG6lfvO5gb4hGjG3OKXX37B2LFjuYi5\nYOvWrYiKihIdo9HS0tLcOp+nJSQkAICpZyNJEiorK029I4V578pWT2jAgAH1XlNMTAwA+aKwDWWQ\nJMli03tlZaXFPGq1GkVFRdDpdABu9tCU/B5BjDFq3ry56Ah+7dtvv6UffvhBdAy/FRcXZ3ea8jEN\nwHRTpKenW0x3xHy6vXl1Op3dZcypVCqLx2q1mjIyMkyZDAZDvXmU6bY4ev3O4ELGgt6nn35KP//8\ns+gYfq9du3ZuaUf5sE5PTzc91mq1pNPpCADl5eURkfyBmZGR4fBDWaVSkUajoZSUlHptKR+01u0o\nxUH5UM/KyrL4qbRBRJSXl2cxr6ucLWSOnne2kGm1WptFRXl9tpaxpryfTcljjgsZY00UGRkpOkJA\nMBgMNj8MXZGenm4qFuYFxPynUjwcfWDa+lBtqB3lsfXzjtpo6sYtex/kSvFW1mHeIwNAR48erffY\nnoyMDDIYDBZFSK1Wm+7bK2QGg8FiuvJ7ISLTlw3zdqzfE+WLh0ajsZuNCxljTbBx40a6ePGi6BgB\no2PHjm5ry/xDVHlsTqVSOd0LcVSErNtRHpv3CBtqw1OFLFg09fXzwR4sqC1evBht27YVHSNgzJo1\ny+kj1Zyxd+9eu9M0Gg1SUlKwYsWKJq3Duh2NRoOSkhLMmzfPqWUlSUJWVlaD8/brB/zzn8CNG02K\ny2zgQsaCGo+j6F6vvvoqHnzwQbe0VVhYiLNnz1o8Z34UXlpaGtauXWsxzZz1Se16vd70nPk063bS\n0tIQGRkJrVZbry2j0Qij0Wh6XjkSb9KkSQ2eRH/wIDBtGtC8OdCsGSBJwB13AK+9BtTWtne4LHOM\nzyNjQWvWrFlYs2aN6BgB56GHHsLu3bub3I7RaERERIQbEnmOcv4V0PB5XNHRgK3hKcPCgDvv/C0O\nHfqXp2L6PD6PjDEXNeXS6sy+zz77DP/4xz9cXj4tLQ2SJCE9Pb1Ry1VUVLi8TleYnxdVUVEBIgIR\n8OWXwPPPA127yr2uO+8E5s0Dhg2r30Z5ubypMSzsgheTBx7ukbGgdOzYMVy8eBH33HOP6CgBqTGj\nOvijkycBjUa+5efLmwp/9ztApQLGjgU6dqy/zM6dwGOPycVtxw55fkVTeyT+rqmvn0e/Z0EpMTER\nJSUlomMELLVaLTpCk9XUAF98AWzfLt90OqBvXyAhQb7NmSPfnPXII8CqVQBfl9T9uEfGglKvXr1w\n7Ngx0TEC2pIlS/Dyyy+LjuHQjRvAZ58Bubly76qqCujfH+jdWy5WKhXgjd103CNr2uvnQsaCjtFo\nxL59+zBmzBjRUQJaWFgYampqRMcAABw6JBeq7duBoiKgVaubmwFVKqBNG7H5uJDxpkXGGuXFF1/E\nunXrRMcIeKNGjfLq+q5du9mz0mgAoxEYNOhmsZo/X76xwMM9MhZ0QkJCUFdXJzpGwMvPz0dcXJzb\nR8YvKZEL1vbtwLffypv+lP1WKhXQooVbV+cVEydODOiDYxoiSRI2bdrk+vJcyFiwGTRoEL799lvR\nMYLCSy+9hDfeeKPRy12+fLNY5eYC1dVAfLzcu0pIAO6+2wNhmd/iQsaCzurVq/H888+LjhEUoqOj\n7Y54YTTe3BSYmwtcvSqfa5WQAMTGyoenN2vm5cDML3EhY0Hlyy+/xKBBg3DLLbeIjhIUJElCYSGZ\n9lsdPAjceuvNntXo0fLIFow1Bf8JsaCSm5uLhx9+WHSMoDFkyBjceiuweLF8Y8wTeIgqFlT27Nkj\nOkJQeeihQejeXXQKFui4kLGgUl5eLjpCUBk2bBgMBoPoGCzAcSGzYf/+/Zg9ezb69u1rumxEZGQk\nevbsicGDB6Nnz57o0qWLaVr79u0xbtw4rF+/HtevXxcdn3mJMrhtaWmp6W9BuSUkJFgMYms93fqS\nI0VFRTafN6fX6yFJErKzs+3Ok5mZabqv5EpNTbU7T2pqqsV0o9GIoqIiiwFxmyI2Ntbrg/myINSk\ny3IGAL1eT5MnT6aoqCiKiIighQsXWlzKuzFqa2tp8+bNNGLECAJAKSkpdOnSJTcnZk0RFhbmlnZU\nKpXFYzi4irCtx+np6fUuGW/r3zErK6veJejt/dsaDAaLabYuLW8+j/l0R1mbauPGjW5rizFbgrKQ\nXbp0iYYPH04dOnSgnTt3enRdmzdvptatW9OYMWPo6tWrHl0Xa1hEREST21Cr1aTT6WxOc7aQOXqs\n0+koJSXF5jq0Wq3dIlNYWFhv/QAs2rGeh0gubtZFz52FbM2aNW5rizFbgmrT4scffwxJkrB+/Xrs\n3bsX586dw+jRoz26zsTERFy+fBk7duzAihUrEBISgoKCAo+uk9nnjgs1vv7664iOjrY7XdlESE6e\n2ZKWlub0umNiYqBWqy02DwLy5sL4+HiL50j+oooZM2bYnQcAkpOToVKpnM7QWOZXVPY2SZJQVFSE\nyspK0yZUZbNpQkKC0GzMjQQXUq949913KTw8nI4dOyY6ChERHThwgEJCQmj79u2iowSdmJiYJreh\n0WiopKTE5jSY9arUarXNaQqtVktZWVmmTYy2/h1tbVq0NS/+2/tSbuZSUlLsztPQ63CHJUuWuK2t\nxoKNHrLy02Aw1NtEzPxTQJ9H9v3332PQoEE4fvw4rly5IjqOyaBBg1BbW4vvv/8eISEhOHXqlOly\n6cyz3PENXKVSISEhAenp6YiNjUVlZSXCw8NNvTS9Xo/o6GgkJiYiMzMTM2fOtFivMtJFTEwMunbt\nCiKyO/pFUlKS6f6KFSswd+5cpKWlmXp7aWlpWLhwoemx0hPMzs5GUlISKisrsXbtWgCoN49er8fA\ngQNN7SvT3d1LcUcv2BMiIiLQuXNn0TEsSJKEJ598UnQMr9m8ebN7xpgUV0M9KyYmhtavXy86hlOW\nLFlCLVu2pAMHDoiOEvAC+E/eJ9XV1VFOTo6w9QMgg8FgcZCLSqUinU5ns6crWlxcnOgIXuWu1xtw\n+8i+/vpr3HbbbdBqtUhOThYdxynz589HdXU1Dhw4gPvuu090HMbc5scff0QcEVBbK2T9RISIiAhE\nRESYvvlrNBpER0db9HaZfwuoTYujR4/G+PHj8fPPP4uO4pJnn30W06dPR2hoKKqrq9HCH69HwZiZ\nw4cPY3RsLPDJJ0B5OVBaKt+0WnmGjh2Bfv2AAQPkW79+8iWa+W+fNULAFLLWrVujsrISHTp0EB2l\nSZo1a4ba2loMHDgQmZmZuPfee0VHchtlf467520MW0ftMc/Zt28fxo4dCwwcCDiz7+fECWDnTuDs\nWcvCd+mSPD029maxGzhQvt+zp2dfBPN5fl/IiAjNmjXzmUuqu0tJSQnmzJmDAwcO1BuZwV81pjB5\noogB3r9qcbDLy8tr3AI9esg3Z1y7Jhe799+/WfAOHgSqquTpXbtaFrz+/YG77mpcHuYX/HofWU1N\nDdq1axdwRUzx5ptvolWrVlCr1R5fl/VQRnq9Hnq9HtnZ2cjPz0dpaSlWrFgBwPF5T8qQTUVFRab2\nlGGXlJ/W7SiPjUajaXgn85/my+bm5qKoqAjZ2dkOh3OyZ/z48Th58mSjl2Ou+f777z3XeIsWwODB\nwB/+AKxcCRQUAHo9QCTfTp2Srx3z2mvAE08A168DGzYA8+YBjz0G3H47IEnyrXNn+QJoL70EfPgh\nsHs3oNN5Jvd778kFmLmPWw4ZEaCurs4tozT4g23bttHChQs9uo6SkhLTUV3p6elEJB/dBbPzjlJS\nUho80gsOzttRflq3ozw2GAxOLWtrXY3x6quvurQca7xevXqJjuCac+eI9uwhevNNoj/8gei++4ha\ntJBLpCQR9etHNHky0dKlRJ9+SnTmjPNtDxmilFoiq/8nPmrRNX5byJ599lkqLCwUHcNrQkNDPb6O\nlJQUMhgMFifQmjt69CgBMBU6W5wpZNbtKI+dWbakpISysrKopKTEYQ5HnnjiCZeWY40XcO/14cNE\nOTlEaWlECQlE3brdLEodOxL99rdEc+YQ/eMfRP/+N5GtYenMl5Ekor//3TSJC5lr/LKQbdy4MShH\nxWjevLnH12FeTDIyMkyjU5gPamtvNAjr5e0VI+t2GrOMrYFwbeeQb82aEYWGyvebNye6/34iQNx5\nTcHk9OnT9PXXX4uOIc7x40TbthG9+irRE08Q9e598w/T+tasGdHUqXY/2FNSUpzeApGXl2caNcYW\nnU5HAOyOGGN+s35ekZGRYTOP+fOFhYUNjpwStIXs5MmT9MILL4iOIURNTQ316dPHo+uw/sNTq9UW\nPbT09HRTT0itVtscBd76H8H6Oet2lMf25jd/TtkEav2PZS0tzfbnhSQRDRnymBveKdaQ559/XnQE\n32SvmPXvTyMd/H87W8iaMp8yXJqtIdYU5rsBzNuwNX9DWYK2kHXr1k10BKEOHTpEy5cv91j7eXl5\njZpf5OZd831qii++IBoxov5nRFgYkfJ/VlhY6PKlepjz/HgXvGcp36j69iWy2sLg6INdeT+VL4/m\nX/K0Wm29XQK2vkAqHF1FgchyX7RGoyEA9dZrva6MjAy7lzeyJygLWbt27URH8AnPP/88Xbx40a1t\nKn+Ivi4rK4sAmL79ffCBvMUmNJRo9myin366OW/z5vJnRsuWRLW1lu2MGzfOi6mD08SJE0VH8DvO\nFDJbhcl6i4Yz1Gq13f95W5cQUuYtLCy0WTSJ5N0FjTkgK+gK2dKlS0mv14uO4TNatGghOoLXXb1K\ntHgxUUSEfFuyxPa+dAVAZO+ajsH4/nmTRqOhCxcuiI7hd5wtZI6eb0xP2Na8jRmDUvlCad6Oea/M\nW4XML84jIyKUlpYiKipKdBSfcfnyZcyaNUt0DI/6+WfghReAsDCgTx8gOxt4+WXAYJBv8+c7HsmI\nCJg82fa09957D1evXvVMcIYpU6agffv2omMEDOurIyjXvFNUVFRYTLd+bM78PE4yu4qCPfn5+QDk\nczgVynmlysAFarUaer0emZmZ0Gg0ALx8HTq3lEMP69Spk+gIPmnu3LlUV1cnOoZb1NQQHThANH68\n3JMaOVLe3+VJv//97z27giCWnJwsOoJf4sPvXePzPbLjx49jy5YtomP4pPT0dHTp0kV0DJecPw+8\n+CLQvLk8klBmJhAeDmzZIvek8vOBhx/2bIZjx455dgVBatGiRfjnP/8pOgYLIj5fyHr37o0hQ4aI\njuGz3nrrLZw/f150jAYdOgQkJ8ujAQ0ZAuzbByxbJo8apNUCKSlA377ezVRYWIjt27d7d6VBYOnS\npS4NH8aYq3y6kBUXF+PIkSOiY/i0xx9/3CevLr17N/Dgg3LhGj8eqK6Wh7kjAr75BkhIEJ0QaN++\nPRITE0XHCChFRUWeHV+RMRt8upDFx8ejV69eomP4vDVr1uDKlStCM6xfD9x9NxAaCsyeLR+ckZcn\nF65PPpHHdvVF3377LQ4ePCg6RsAYNmwY/88yr/PZQnbx4kXk5OSIjuEXpk6dioEDB3ptfdeuAW+8\nAURGAu3bA4sXAxMmyJsPa2uBt96SBxP3B/379/fqexfISkpKUFZWJjoGC0I+W8hGjhyJJ554QnQM\nv3GXB6+zdPYsMGeOfBh8797yYfAvvQRcuCAfBv+Xv8gHavir48ePo6CgQHQMv/fAAw/g7rvvFh2D\nBSGfLWTh/vzJKMCWLVuQmZnplra++06+mK8kASNGAGVlwJtvAjU1wNGjwNNPu2U1PiMmJgbJycmi\nY/i1zMxMnDt3TnQMFqR8spB99dVX2Lx5s+gYfiUsLMylK0lfuCCfWBweLheuyZPlQ+I3b5b3b+3Z\nAzzyiPvz+prTp09jypQpomP4rQ0bNqB169aiY7AgFSY6gC3Jyck4deqU6Bh+x5kP4sOHgSVL5CMI\n779f3iy4dKl8C2aSJKFPnz7o1q0b/+01Uo8ePXDixAnRMQJCeXk5JkyYIDqG15S76UrZEtF/xyjx\nITExMaisrBQdw++cP38excXFGD16tOm5/Hy5cO3eDYwbJw/xdN99AkP6uJKSEhw/fpz3zzpp69at\n6NatG37zm9+IjsKCmM8VstraWmzYsAHTpk0THcUv9e79AsLCVuHIESA1VS5c/nIEoa946KGHsGvX\nLoSGhoqO4tNqa2sxevRo7N69W3QUFuR8rpC9/fbbeO6550TH8FshISGoq6sTHcPvNWvWDDdu3BAd\nw6fxe8R8hc8d7LFu3TrREfwabxJzj+vXr+POO+8UHcNn3Xnnnbh+/broGIwB8MFC5q6df8Hqqaee\nEj7KRyCQJAkFBQUYO3as6Cg+Z+zYsSgoKODxFJnP8LlCxsPbNM2YMWOwc+dO0TECwh133IE5c+bg\npZdeEh3FZ7z88suYM2cO7rjjDtFRGDPxuUI2cuRI0RH8WvPmzXmUCjcaNWoUBg0ahGXLlomOIlx6\nejoGDBiAUaNGiY7CmAWfK2SDBg0SHcHvFRcXi44QUCZMmICuXbti7ty5oqMIM2/ePHTu3BlJSUmi\nozBWj08VsqqqKsTGxrq8vF6vt7ndXnmutLTUdD87O9timvlz5suVlpbWm26+jK31mV823Hyd1hIS\nEizOl8vMzIQkSRaXFHcFXzDS/SZOnIjf/e53FufoBYvRo0fjsccew6RJk0RHYcwmnzr8vry8HM2a\nNWvSALiSJMH6JZk/Zz3d1vwAYDQaERER0WB7lZWViImJQWlpKT7++GMsXLjQYl69Xo9bb721Xhup\nqalYu3ZtvXYLCwsRHx/fyFdtyd5rYk33008/4d5778V//vMf0VG8onPnziguLsbtt98uOgpjdvlU\nj8xoNKJVq1Zub/fo0aOQJAnZ2dlOf8DPnz/fqfliYmKwYsUKDBgwoF4Ry8zMRHR0dL1lVqxYgZSU\nFBiNRovemsFgwKeffuq2wX+Z+91+++04c+YMwsLCUF1dLTqOx1RXVyMsLAxnzpzhIsZ8nk/1yPbt\n24fu3bujcxOGonDUGykqKsIDDzzgVI/MvMAcPXrUYpOnrWWse2S5ublQqVQ253fUQ2zoNTiDe2Te\nMWLECCQkJOBPf/qT6ChuQ0RYuXIltm/fjj179oiOw5hTfKpHFhER4dZzoIqKigAA+fn5AOD0JrvU\n1FQQkek2b968Bpcx75GlpaWZipgteXl5FvvebE1nvm/Pnj0YPnw42rZtGxCjqaxatQp9+/bFsGHD\nuIgx/0I+pKysjMrKylxeXqfTkflLUu4DIIPBQAaDgaxfMgDS6XQWz6nV6nrzNLSMI8ry5u2qVCqL\nn1lZWUREpNVqnW63ofUx70hLS6P4+HjRMZqkrKyMmjdvTlevXhUdhbFG86lNi1evXsWuXbt4NIUm\n4stqeF9dXR3uuOMOqNVqzJo1S3Qcp9XU1KBTp05YtmwZpk+fLjoOYy7xqeuRhYeH48cffxQdw+/x\nGIHeFxISgp9++gnHjx9HWFgYNm3a5NPjXhIR+vfvj9/85jd8ZWfm93xqHxkgH/DBmmb48OGiIwSt\nnj17oqamBr1790aLFi3wxhtviI5kwWAwoHPnzvjDH/6A8vJyrF+/XnQkxprMp3pkAHgncxOdOXOG\nhxDyAf369cO1a9dw+fJlDBkyBOfPn8fOnTvRrVs3IXmWLl2Kl19+Ge+++27QnAPHgofP9ciMRqPo\nCH7t448/xpAhQ0THYP/Vpk0bfPPNNzhy5AhOnjyJqKgo3HPPPdi7d69H11tTU4O//OUvCAkJQUpK\nCv785z+DiPDMM894dL2MieBzhSwhIUF0BL+2ceNG0RGYHSNHjkRVVRW+++47xMbGYvr06ZAkCffc\ncw+WL1/epJ7SF198gaeffhrNmzdH7969sXHjRixevBh1dXV45513+GrXLKD51FGLgHzOV1xcHKKi\nokRH8Ut8MrT/+vrrr7F7926cOnUKX331FY4fP+5w/p49e2Lo0KF48MEHkZCQgPbt23spKWO+xecK\nGQC89NJLPreT3F9MnTqVd+AzxoKKTxaykJCQgBgpwdsKCgrQt29fm+M7MsZYoPK5fWQAkJiYKDqC\nX3rhhReEFzG9Xo+EhATk5uZa7O/Mzs6GJEnQ6/UC0zHGApFP9sh+/fVXfP7551zQGmlb+/YYN3Qo\n8NFHQESEsBzKfjrlZ35+Pvr164fo6Gjeh8cYczufLGQA0Lp1a/z666+iY/iN0tJShIeHo3fv3sA/\n/gH8v/8HPPEE8MEHQMuWXs1iXcgaGu2fMSazdxHeQOaOzwOf3LQIyJvJmPNGjhwpFzEAmD4dqKkB\nNm0CMjOBkBDgmWfk5wTIysoyXYmAMWZfXFycxZU3Av0WFxfnlvfNZwvZkiVL8PTTT4uO4TfsDvj6\nwgtAXR3w3nvAsmWAJAFz5gAe6hVZf6OUJAlJSUkoLy+HJEkwGAweWS9jLHj5bCEDgPLyctER/MK4\nceOQnp7e8Ix/+YtcwN58E1Cr5aL2f//n1izKNy3r+zNnzgQRIULgvjvGWGDy6UJWXFyMRYsWiY7h\n81zarr5okVzUXn9d7qFJEtC/P9DASbiMMeZrfLqQhYaGIicnR3QMn5aYmIitW7e63oAkyT00IqCs\nTC5kt9wCDBkC/PST+4IyxpiH+HQhA+Sj8aZNmyY6hk8iInTv3t29jT7yCHD+PPDNN8D+/UDr1jef\nY4wxH+Rzl3GxJTIyEjU1NQgL84u4XtOpUyfodDrPreDxxwHlFIgNG4AZM4AxY+T7rVt7br1BiIjw\n/vvvY+3atTh48CCuXLmCe++9F/369UNsbCxa//f9/vXXX1FRUYFDhw5h//79aNmyJZ566inMnTsX\nffr0EfwqGBOE/ETLli1FR/ApX3zxBR08eFDMytesIQoJIUpOJrp2TUyGAPDTTz/R0KFDqU2bNrR6\n9Wqqra11ua3y8nIaO3YshYSE0JtvvunGlMyb4uLiREfwKne9Xp/ftKg4deoUH/hh5sUXX8Tdd98t\nZuWpqUBtLbB+PbBqlbyfbdYs+TB/1qDXXnsNYWFhKC4uxr59+3Dp0iU899xzCAlx/d+xX79+2LZt\nG2pra5GamoqxY8eiU6dOPCRYgEhNTXX6oK78/HxUVlYiOzvb7jzKMHL2ZGZm1rukVmZmpul+bm4u\nJEmqtw7zeTIzM713grdbyqGXPP/883ThwgXRMYRr166d6Ai2LVhABBDNmyc6iU967rnnqHv37vTr\nr796bZ3vvPMONW/enM6cOeO1dTLXOeqhOPtx3dB8yvSSkhIqKSmpN12tVtd7zmAwWLSr3Dd/znye\nrKwsMhgMDeZxV4/MrwoZEVFERIToCEJNmDDB9Afi0+bOlYvaggWikwi3ZcsWatOmDV29elVYhiVL\nllBMTIyw9TPnOFPIVCqVxWOKi+3LAAASpUlEQVQApNVqKSUlpd7z1jfz6eZtma8jIyODVCoV5eXl\nmZ4vLCy0WE6tVlNhYSHpdDqb89gqeo19vY3hd4WMiKhVq1aiIwiRlZVFmzZtEh2jcWpriVJS5KK2\nfLnoNF4XGRlJu3fvFh3DpGfPnrRlyxbRMXyCrZ5HU+ZzB2cKmXVhIiJKT0+3WUQctWNrXvPemnI/\nIyOj3rzp6elkMBhMhdB6nsLCwnqF1ZagLmTXrl2jPn36iI7hVT/88AOlpqaKjtE0167JB4iEhMgH\njASwH374gTp16iQ6hk05OTk0ePBg0TGYDc4WMkfPO1vItFqtqQBZT7Nuz16vztE8CkdfBIK6kBER\n6fV6uv/++0XH8IrTp0/TqFGjRMdwr8uXiR5/nKh5c6L160Wncav09HT64x//KDqGQ1evXiVJkkTH\nsEn5MExPTzc91mq1pNPpCIBpk1d6ejplZGTY/eDW6XSkUqlIo9FY9A6UtpTehHU7Su9G2WyWlZVl\n8VNpg4goLy/PYt6msvfBrrx2Zf3WReXo0aP1HtuTkZFBBoPB9J4Q3Sw2arWadDqdafOiuYb2kVk/\nLikpMf0OG/t6G8tvCxkR0YkTJ+iee+4RHcOjjhw5QvHx8aJjeNYvvxA9/DBRaChRUhLRlSuiE7ls\n2rRp9Mknn4iO4bTw8HC6fv266Bj1pKenm4qFeQEx/6kUD0c9EEf7bOy1ozy2ft5RG+46bo4Pv3eN\nXxcyIvmPrUuXLqJjeMTOnTtpzJgxomN438qVRJJE9MwzRDU1otM47dFHH6Xvv/9edIxGu+222+ia\nD54PCMDiwCbrYqFSqZzejOaoCFm3ozw27xE21EZjClmXLkR/+xvRyZP1p3Ehc43fFzIiokceeYR2\n7dolOobbhYWF0Y0bN0THEOPUKaLBg4mioogKCkSnaVBdXR1FRUWJjuGSH3/8kSZPniw6Rj0ASKPR\nWDy2lpKS4nDzlTNFyFY75gc7OGpDo9EQAFOv0bnXRdSsmfwzLo7o9deJDh2Sp3Ehc43fnBDtyK5d\nu1BSUoLk5GTRUdzi7NmzaNu2LW7cuBG8w3J17QoUFwN6PRAdDfTpA3TrBhw4IDqZTeHh4X578nGv\nXr0wffp0LF26VHQUC4WFhTh79qzFc5IkmU6yTUtLw9q1ay2mmbP+fej1etNz5tOs20lLS0NkZCS0\nWm29toxGI4xGo+l55aThSZMmOf37DwsDbtyQ75eXy1dUuvtueVyBM2decaoNZkki8tAVFgWorKxE\n3759cenSJdFRXPbXv/4VP/zwAz755BPRUXzTv/8NJCYCbdsCW7YAd90lOhFatmyJK1euiI7RZGvW\nrMGwYcPQv39/0VEAyEXD169fV1lZiZiYGAByIbX3cXr5MvDRR8DGjYBOB1RUWE7v2FF+fuDA/igr\nK/N0bJ/Rv797Xm9A9MgUMTExuHTpErp27epweBZfVFNTg9atW2PSpElcxBy57z6gshI4eBD4+Wcg\nKkp+7vRpIXFUKhUuXLggZN3uNmvWLEycOFH4lo20tDRIkuTcxWLNVFhXBw8zH8KpoqLCVMS++gp4\n9ln5u1ZoKPDkk8CXXwIzZwJ79wKrV99sQ5IArRaoqgKaMEIZc8sGSh/0r3/9i9q0aUPV1dWiozhU\nVVVFYWFhNGzYMNFR/JtGQ9S2LdGIEURVVV5ZZUVFBa0PsFMHiOTDsw8fPiw6hs+rqiL6+9+JBg2S\n93fdfTfRkiVE/z3Y0iGAyNbBrbyPzDUBtWnRlmeeeQZlZWUoLi4WHcVCTU0NevfujYkTJ2Lx4sWi\n4wSW7Gxg2jTg4YeBDz8E2rXzyGqioqJQVVXlkbZFi46O9tt9fp6wa5d89aKcHLkXNXEikJws/4m5\nk7s2tfkLt71et5RDP/Doo49SXFyc8MOML168SF27dqXk5GShOYLGu+965Py0mTNnuq0tXzVjxgzR\nEbxOoyGaMIHorrvkXtPgwfLZIL/84p31c4/MNUGzVfbzzz9HWVkZXnnlFYSGhuLjjz/26vrfe+89\nSJKEd955B6dOncL69eu9uv6g9cwzQE0NkJUFrFsn74iYMUO+DA1zKJCPmD1+HHjlFaBXL7mHNXQo\nsHYt8NvfAps2AYcPA0TygbNz5gC33CI6MXMk4Dct2nPu3DlMmDABxcXFWL58OR599FF069bNretY\nvnw51Go1xowZg/Xr16NNmzZubZ81waJF8nHPc+YAf/+7/GlmTpLkY6P79au36P/8z/9g7969Xgoq\n1rBhw7Bv3z7RMVxWUwN88om8WXDHDiAyEpgyRb7dd5/odPV9/PHHdo98DESSJCExMbHpDbmlX+fn\nampq6JtvvqGEhAQCQAMHDqRly5bRd99959TyZ8+epezsbJowYQKFhYVR586dadWqVR5Ozdxm/nx5\nO9L//R9RWRnRSy/JjyWJaM6cerNPnTpVQEgx/Om1lpQQvfgi0W23yb++hx4i+uADIoFXz2FeErQ9\nMmccO3YMBQUFOHToECoqKqDT6XD16lWEh4cjMjISnTt3Ru/evfHAAw9g+PDhCA0NFR2ZNUVdHfDN\nN8Dw4ZbPR0fLJ/kAmD17Nt566y0B4cSZNWsW1qxZIzqGydWr8jlZH30E5OUBnTvf7GXZ6ECzIMCF\njDFzdXXyyT/WJAm4fBm33HEHzp8/7/1cAnXo0AG//PKLkHUXFcmbBT/6CDAYgIQEuWCNH2/718SC\nU9Ac7MGYU5Yvt/08EdC6NXJycrybxwds2rTJ46cZ7N1reRJxbCzw2mtyZ/jtt4ELF+Rfwfbt8gnG\nXMSYOe6RMeak3//+99ixY4foGEK467WfOyf3sD78EPj2W3mMweRkYPJkoEsXNwRlQYkLGWNOCgsL\nQ01NjegYQrjy2r11EjFjgXuiCGNulpKSIjqCMLNmzbI7TauVe1gbNgBHjgCDB8v7sZKTgdGj5YFy\nGfMk7pEx5oTvv/8ebdu2Ra9evURHEeLkyZM4d+48Tp8ehA8/BLZuBdq0AZ56Si5aw4aJTsiCGRcy\nxpwwd+5crFixQnQMoR55JAtbt05C69aikzBmiY9aZMwJn3/+uegIwp06tYCLGPNJXMgYc8Lhw4cb\nvYxyNWPrm7nU1FTT/crKynrz5efn21zOug3zdszbUK7Ll5uba/HYFT/++KPLyzLmSbxpkTEnOLr6\nrzPLKPetr3qcm5uLs2fPYubMmabn9Ho9ZsyYAY1Gg8rKSoSHhyM6Otpi+oIFC/Dqq69i//79UKlU\nFutQrlqs1+tNyynTXHkdTXkPRJMkCYWFhbj99tuxZMkSrF27FgkJCdBoNEhISMCGDRuEXYW6vLwc\nmzdvRlxcnJD1+6Ly8nI8+eSTjX5PuJAx5oSmfojbWj47OxtJSUk2p+Xm5qJ169bo16+fqRgpvamk\npKR67RuNRuzdu9dU1AC5p7Z27VoA8lWXx4wZgx49elgUxcZo2bIlrly54tKyotj6MmH+pSI5ORka\njUZItvLycgDgQmbG1feENy0y5gRPfGt3VFBUKhVWrlyJFi1aONVWcnKyRREDgFdffdV0v3379ujT\npw9mzJjhWlgg4K7eEBERgc6dO4uOwdyACxljTnD3houioiKMGjUKAFBSUlJv31VmZiY0Gg3at29v\nei4pKQlJSUnQ6/VITU01XcG5tLS0Xq8iOzvbolDOmzcPERERyM3NdTnzjRs3XF5WJKPRCKPRaHqs\nUqmg1+uRnZ1t6rEy/8YnRDPmhIsXL7q8rFJwzH366aeIj48HAAwYMAADBw5EUlISSktLkZaWZipM\nBoOh3qbH6Oho0wewXq/HwIEDTdM8uaegt9EoD4jYrZvl7bbbPLbOpjJ/P5T7yntraxMt80+8j4wx\nJ/jjgQ7uVu89OHMGOHWq/u3kSflnXZ08X8uW9Ytf9+4370dFee9F+BDeR1afq+8J98gYc0LLli1F\nRxCu3v66O+6Qb64O63HqFHDwoO1iaDAAZpsD0aWL/WLYvbtr62cBgwsZY04YMWKE6AjCjRw50r0N\nKgXJVefOyUXvwAHbxbC6Wp5Pkix7gNY3Tw+7L0nAnXfKw/23bevZdQUpLmSMOWHSpEmoq6tDSEhw\nHh9VV1eHiRMnio5hqWNH+TZ4sGvLnz0rF7yvv7bcJKr0CM33bUZF2d4sqtwc9dhbtAB+/BFo104u\natu2yVcItcP8PEJnFBUV4YEHHkBJSQkGDBjg1DKBJjj/KxlrpLi4OBw7dkx0DGFOnDgRePtyOnUC\n4uOBpCRg/nxg3Tr52jNHjwI6HfDrr/Kmz08/BV55BVB65fn5wF//Cvzud/IF1Vq1qt9WRgbwxRdA\nRQVQW3tznUTAuHHAsmV2Yy1YsKBRR5c+8MADICKkpaXZnJ6bm4sEO4XTepqjUWgyMzNNz5nfVyQk\nJFi0ZT2ajF6vb/LoMnYRY8wpzz33nOgIwgTza3eZwUBUUkIkly+bt7KyMpuLNuaj2dG8Wq2WCgsL\nbc5na5pWqyUiIp1OR2q12jSv+f2srCwyGAwWy5m3rVKpbE5TfpaUlFBeXp7NvGVlZXbfE0e4kDHm\npJCQENERhAnm195kSuFq1owoNJTotdeIamsdfmgrH/o6nY6ysrIoLy+PSkpKKCUlhXQ6nUXhMC8U\n1reUlJR68ykaMy0jI6NegbJ1Pysry/RYrVZTYWEh6XQ6h8uZc7WQ8T4yxpz02GOPiY4gTDC/9ibr\n0wfYtAlwYdPsjBkzLDYz0n/H0rSFbJweIkmS3ZO+33nnHbvTzEeFAYCZM2fivvvuQ2pqKgoLCy2G\nP1NkZWXh4MGDpvFEldFkzIcBMxqNOHXqFNLT0+2/aFc0uvQxFqTOnTtHO3fuFB3D63bt2kVVVVWi\nYwQcZ3pkAOjo0aOm57Oyskir1TrVuyEiysjIsNkjcjTNvFdlPU3plSmUTY7KPAaDwe4mRUV6errd\nvK72yPhgD8ac1KFDB987cs8LJk6ciI4dO4qOETSUkWD0ej10Oh169+4NSZJQWVmJjz76yGK+0tJS\nh23NnDkTCxYsgNFoREZGBgCYDgqxNc0WtVoNvV5vGjYNkIdFW7FiBRYuXAgAyMvLQ3Z2Ng4fPoy8\nvDyb7RiNRqSmpmLu3LlOvhPO45E9GGuE//3f/8XKlStFx/Cq2bNn46233hIdI+DwyB718ej3jHnB\nypUrMWXKFNExvObpp5/mIsZ8HhcyxhrpP//5j+gIXqPVakVHYKxBXMgYa6SCggJMnz5ddAyPe+aZ\nZ7Bnzx7RMRhrEBcyxlzQqlWrgB4Nv7a2Fh06dBAdgzGn8HlkjLlg9erV6NChA3755RfRUTyiQ4cO\nMBgMomMw5hTukTHmov3792P16tWiY7jd2rVrceDAAdExGHMaFzLGXNSrVy+UlZXBaH7dLD8XGxuL\n4uJi9OrVS3QUxpzGmxYZa4KMjAy0adMGly9fFh2lyZYtW4bt27ejT58+oqMw1ihcyBhrosuXL6NF\nixa4du2a6Cgu+/LLL1FXV8dFzItatWrFPV8bKioqGr0Mj+zBmBsQEW699VbT8EL+pKKiAq+99ho2\nbtwoOgpjLuFCxpibXL16FVFRUbh06ZLoKE7Ly8vDqlWrsH37dtFRGHMZb1pkzE3Cw8Nx8eJFhIaG\notb8qsA+6q233oJOp+MixvweH7XImBtJkoTa2lp07NgRR44cER3HroEDByImJgavv/666CiMNRlv\nWmTMQ1588UVUVVXh/fffFx3F5PLly2jXrh2uXbuGZs2aiY7DmFvwpkXGPGTZsmXQ6/WQJAlarRYx\nMTFC8zzyyCPo0qUL6urqhOZgzN140yJjHhQdHQ0iQk5ODm677TYhh+ivWrUK7du3x2effYb33nvP\n6+tnzNO4kDHmBfPmzcPPP/+Ml19+GZGRkTh58qTH1zl//ny0adMGiYmJMBgMCAvjDTAsMHEhY8yL\n/va3v+HChQs4ePAgmjVrhilTpqC6utpt7Ws0GrRr1w7jxo3DokWLcPnyZdx+++1ua58xX8QHezAm\n2JYtW/DHP/4R58+fx4wZMxAXF4fx48cjMjLS4XIXLlzAJ598gg0bNuBf//oXpk2bhhUrVuCWW27x\nUnLGfAMXMsZ8DBEhLy8PBQUFKC8vx4kTJ3DlyhUAQMuWLdGjRw/069cPo0aNwoMPPghJkgQnZkws\nLmSMMcb8Gu8jY4wx5te4kDHGGPNrXMgYY4z5NS5kjDHG/BoXMsYYY36NCxljjDG/xoWMMcaYX+NC\nxhhjzK9xIWOMMebXuJAxxhjza1zIGGOM+TUuZIwxxvwaFzLGGGN+jQsZY4wxv8aFjDHGmF/jQsYY\nY8yvcSFjjDHm17iQMcYY82tcyBhjjPk1LmSMMcb8Ghcyxhhjfo0LGWOMMb/GhYwxxphf40LGGGPM\nr3EhY4wx5tf+P0HlLhiNMBZUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27cb8e62550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the last tree sideways\n",
    "xgb.plot_tree(xg_reg, num_trees=9,rankdir=\"LR\")\n",
    "plt.rcParams[\"figure.figsize\"] = [10,10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs4AAAJhCAYAAABRpjYXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27cb8eb1ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing feature importances: What features are most important in my dataset\n",
    "\n",
    "# Create the DMatrix: housing_dmatrix\n",
    "df = pd.read_csv('datasets/ames_housing_trimmed_processed.csv')\n",
    "X, y = df.iloc[:,:-1],df.iloc[:,-1]\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {'objective':'reg:linear',\n",
    "    'max_depth':4\n",
    "}\n",
    "\n",
    "# Train the model: xg_reg\n",
    "xg_reg = xgb.train(dtrain=housing_dmatrix,params=params,num_boost_round=10)\n",
    "\n",
    "# Plot the feature importances\n",
    "xgb.plot_importance(xg_reg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap 3: Fine-tuning your XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why tune your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untuned rmse: 34624.229980\n"
     ]
    }
   ],
   "source": [
    "# Untuned Model Example\n",
    "\n",
    "housing_data = pd.read_csv(\"datasets/ames_housing_trimmed_processed.csv\")\n",
    "X,y = housing_data[housing_data.columns.tolist()[:-1]],housing_data[housing_data.columns.tolist()[-1]]\n",
    "\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "untuned_params={\"objective\":\"reg:linear\"}\n",
    "\n",
    "untuned_cv_results_rmse = xgb.cv(dtrain=housing_dmatrix,params=untuned_params,\n",
    "                                 nfold=4,metrics=\"rmse\",as_pandas=True,seed=123)\n",
    "\n",
    "print(\"Untuned rmse: %f\" %((untuned_cv_results_rmse[\"test-rmse-mean\"]).tail(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned rmse: 30187.115723\n"
     ]
    }
   ],
   "source": [
    "# Tuned Model Example\n",
    "\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "tuned_params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,\n",
    "                'learning_rate': 0.1, 'max_depth': 5}\n",
    "\n",
    "tuned_cv_results_rmse = xgb.cv(dtrain=housing_dmatrix,params=tuned_params, \n",
    "                               nfold=4, num_boost_round=200, metrics=\"rmse\",\n",
    "                               as_pandas=True, seed=123)\n",
    "\n",
    "print(\"Tuned rmse: %f\" %((tuned_cv_results_rmse[\"test-rmse-mean\"]).tail(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_boosting_rounds          rmse\n",
      "0                    5  50903.299479\n",
      "1                   10  34774.194011\n",
      "2                   15  32895.098958\n"
     ]
    }
   ],
   "source": [
    "# Tuning the number of boosting rounds\n",
    "\n",
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary for each tree: params \n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":3}\n",
    "\n",
    "# Create list of number of boosting rounds\n",
    "num_rounds = [5, 10, 15]\n",
    "\n",
    "# Empty list to store final round rmse per XGBoost model\n",
    "final_rmse_per_round = []\n",
    "\n",
    "# Iterate over num_rounds and build one model per num_boost_round parameter\n",
    "for curr_num_rounds in num_rounds:\n",
    "\n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3, num_boost_round=curr_num_rounds, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append final round RMSE\n",
    "    final_rmse_per_round.append(cv_results[\"test-rmse-mean\"].tail(1).values[0])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "num_rounds_rmses = list(zip(num_rounds, final_rmse_per_round))\n",
    "print(pd.DataFrame(num_rounds_rmses,columns=[\"num_boosting_rounds\",\"rmse\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    test-rmse-mean  test-rmse-std  train-rmse-mean  train-rmse-std\n",
      "45    30758.543620    1947.454953     11356.552734      565.368794\n",
      "46    30729.971354    1985.698867     11193.557943      552.299272\n",
      "47    30732.662760    1966.997355     11071.315755      604.090310\n",
      "48    30712.241537    1957.751573     10950.778320      574.862779\n",
      "49    30720.854167    1950.511057     10824.865560      576.665674\n"
     ]
    }
   ],
   "source": [
    "# Automated boosting round selection using early_stopping\n",
    "\n",
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary for each tree: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
    "\n",
    "# Perform cross-validation with early stopping: cv_results\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix,params=params,num_boost_round=50,nfold=3,metrics='rmse',early_stopping_rounds=10,as_pandas=True,seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of XGBoost's hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common TREE tunable parameters\n",
    "- eta: \n",
    "    - learning rate - value between 0 and 1\n",
    "    - affects how quickly the model fits the residual error using additional base learners\n",
    "    - low learning rate will require more boosting rounds to achieve the same reduction in residual error as an XGBoost model with high learning rate\n",
    "- gamma: \n",
    "    - min loss reduction to create new tree split\n",
    "- lambda: \n",
    "    - L2 reg on leaf weights\n",
    "- alpha: \n",
    "    - L1 reg on leaf weights\n",
    "- max_depth: \n",
    "    - max depth per tree\n",
    "    - must be a positive integer value\n",
    "    - affects how deeply each tree is allowed to grow during any given boosting round\n",
    "- subsample: \n",
    "    - % samples used per tree\n",
    "    - must be a value between 0 and 1\n",
    "    - fraction of the total training set that can be used for any given boosting round\n",
    "    - if value is low, fraction of training data used per boosting round would be low, causing underfitting problems.\n",
    "    - if value is very high, can lead to overfitting\n",
    "- colsample_bytree: \n",
    "    - % features used per tree\n",
    "    - fraction of features that you can select from during any given boosting round\n",
    "    - same as RandomForest 'max_features' attribute\n",
    "    - must also be a value between 0 and 1\n",
    "    - large value means almost all features can be used to build a tree during a boosting\n",
    "        - may in certain cases overfit a trained model\n",
    "    - small value means that the fraction of features that can be selected from is very small.\n",
    "        - smaller values can be thought of as providing additional regularization to the model\n",
    "- n_estimators / no. of boosting rounds is tunable in both models\n",
    "    - either no. of trees to build\n",
    "    - or no. of linear base learners to construct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINEAR tunable parameters\n",
    "- no. of tunable parameters is significantly smaller\n",
    "    \n",
    "- lambda:\n",
    "    - L2 reg on weights associated with any given feature\n",
    "- alpha:\n",
    "    - L1 reg on weights\n",
    "- lambda_bias:\n",
    "    - L2 reg term on model's bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     eta      best_rmse\n",
      "0  0.001  195736.406250\n",
      "1  0.010  179932.182292\n",
      "2  0.100   79759.411459\n"
     ]
    }
   ],
   "source": [
    "# Tuning eta\n",
    "\n",
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary for each tree (boosting round)\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":3}\n",
    "\n",
    "# Create list of eta values and empty list to store final round rmse per xgboost model\n",
    "eta_vals = [0.001, 0.01, 0.1]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the eta \n",
    "for curr_val in eta_vals:\n",
    "    params[\"eta\"] = curr_val\n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix,params=params,nfold=3,\n",
    "                        num_boost_round=10,early_stopping_rounds=5,\n",
    "                        metrics='rmse',seed=123)\n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(eta_vals, best_rmse)), columns=[\"eta\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth     best_rmse\n",
      "0          2  37957.468750\n",
      "1          5  35596.599610\n",
      "2         10  36065.546875\n",
      "3         20  36739.576172\n"
     ]
    }
   ],
   "source": [
    "# Tuning max_depth\n",
    "\n",
    "# Create your housing DMatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# Create the parameter dictionary\n",
    "params = {\"objective\":\"reg:linear\"}\n",
    "\n",
    "# Create list of max_depth values\n",
    "max_depths = [2,5,10,20]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the max_depth\n",
    "for curr_val in max_depths:\n",
    "    params[\"max_depth\"] = curr_val \n",
    "    # Perform cross-validation\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix,params=params,metrics='rmse',\n",
    "                        num_boost_round=10,early_stopping_rounds=5,\n",
    "                        nfold=2,as_pandas=True,seed=123)\n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(max_depths, best_rmse)),columns=[\"max_depth\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   colsample_bytree     best_rmse\n",
      "0               0.1  51764.712890\n",
      "1               0.5  35612.806641\n",
      "2               0.8  35509.833985\n",
      "3               1.0  35836.046875\n"
     ]
    }
   ],
   "source": [
    "# Tuning colsample_bytree\n",
    "\n",
    "# Create your housing DMatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# Create the parameter dictionary\n",
    "params={\"objective\":\"reg:linear\",\"max_depth\":3}\n",
    "\n",
    "# Create list of hyperparameter values: colsample_bytree_vals\n",
    "colsample_bytree_vals = [0.1,0.5,0.8,1]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the hyperparameter value \n",
    "for curr_val in colsample_bytree_vals:\n",
    "\n",
    "    params['colsample_bytree'] = curr_val\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,\n",
    "                 num_boost_round=10, early_stopping_rounds=5,\n",
    "                 metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(colsample_bytree_vals, best_rmse)), columns=[\"colsample_bytree\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of Grid Search and Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hyperparameter values interact in non-obvious/non-linear ways\n",
    "- Two common search strategies are:\n",
    "    - Grid search\n",
    "    - Random search\n",
    "- both can be used with XGBoost and scikit-learn packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search: Review\n",
    "\n",
    "- Search exhaustively over a given set of hyperparameters, once per set of hyperparameters\n",
    "- Number of models = number of distinct values per hyperparameter multiplied across each hyperparameter\n",
    "    - for 2 hyperparameters to tune with 4 possible values for each, total number of models tried by grid search will be 16\n",
    "- Pick final model hyperparameter values that give best cross-validated evaluation metric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:   18.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.01, 0.1, 0.5, 0.9], 'n_estimators': [200], 'subsample': [0.3, 0.5, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search: Example\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "housing_data = pd.read_csv(\"datasets/ames_housing_trimmed_processed.csv\")\n",
    "X, y = housing_data[housing_data.columns.tolist()[:-1]], housing_data[housing_data.columns.tolist()[-1]]\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "gbm_param_grid = {'learning_rate': [0.01,0.1,0.5,0.9],\n",
    "                  'n_estimators': [200],\n",
    "                  'subsample': [0.3, 0.5, 0.9]}\n",
    "\n",
    "gbm = xgb.XGBRegressor()\n",
    "grid_mse = GridSearchCV(estimator=gbm, cv=4, verbose=1, \n",
    "                        param_grid=gbm_param_grid,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid_mse.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'learning_rate': 0.1, 'n_estimators': 200, 'subsample': 0.5}\n",
      "Lowest RMSE found:  28574.9861732\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Search: Review\n",
    "\n",
    "- Significantly different from Grid search\n",
    "- No. of models required to iterate over doesn't grow as you expand the overall hyperparameter space\n",
    "- Create a (possibly infinite) range of hyperparameter values per hyperparameter that you would like to search over\n",
    "- Set the number of iterations you would like for the random search to continue\n",
    "- During each iteration, randomly draw a value in the range of specified values for each hyperparameter searched over and train/evaluate a model with those hyperparameters\n",
    "- After you've reached the maximum number of iterations, select the hyperparameter configuration with the best evaluated score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   41.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score='raise',\n",
       "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "          fit_params=None, iid=True, n_iter=25, n_jobs=1,\n",
       "          param_distributions={'learning_rate': array([ 0.05,  0.1 ,  0.15,  0.2 ,  0.25,  0.3 ,  0.35,  0.4 ,  0.45,\n",
       "        0.5 ,  0.55,  0.6 ,  0.65,  0.7 ,  0.75,  0.8 ,  0.85,  0.9 ,\n",
       "        0.95,  1.  ]), 'n_estimators': [200], 'subsample': array([ 0.05,  0.1 ,  0.15,  0.2 ,  0.25,  0.3 ,  0.35,  0.4 ,  0.45,\n",
       "        0.5 ,  0.55,  0.6 ,  0.65,  0.7 ,  0.75,  0.8 ,  0.85,  0.9 ,\n",
       "        0.95,  1.  ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Search: Example\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "housing_data = pd.read_csv(\"datasets/ames_housing_trimmed_processed.csv\")\n",
    "X,y = housing_data[housing_data.columns.tolist()[:-1]],housing_data[housing_data.columns.tolist()[-1]]\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "gbm_param_grid = {'learning_rate': np.arange(0.05,1.05,.05),\n",
    "                  'n_estimators': [200],\n",
    "                  'subsample': np.arange(0.05,1.05,.05)}\n",
    "\n",
    "gbm = xgb.XGBRegressor()\n",
    "randomized_mse = RandomizedSearchCV(estimator=gbm, n_iter=25,\n",
    "                                    scoring='neg_mean_squared_error', \n",
    "                                    param_distributions=gbm_param_grid,\n",
    "                                    cv=4, verbose=1)\n",
    "randomized_mse.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'subsample': 0.35000000000000003, 'n_estimators': 200, 'learning_rate': 0.15000000000000002}\n",
      "Lowest RMSE found:  28753.2590098\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \",randomized_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \",np.sqrt(np.abs(randomized_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "Best parameters found:  {'colsample_bytree': 0.3, 'max_depth': 5, 'n_estimators': 50}\n",
      "Lowest RMSE found:  30031.6171206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Grid Search with XGBoost\n",
    "\n",
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter grid: gbm_param_grid\n",
    "gbm_param_grid = {\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'n_estimators': [50],\n",
    "    'max_depth': [2, 5]\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBRegressor()\n",
    "\n",
    "# Perform grid search: grid_mse\n",
    "grid_mse = GridSearchCV(estimator=gbm,param_grid=gbm_param_grid,cv=4,scoring='neg_mean_squared_error',verbose=1)\n",
    "\n",
    "\n",
    "# Fit grid_mse to the data\n",
    "grid_mse.fit(X,y)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'n_estimators': 25, 'max_depth': 11}\n",
      "Lowest RMSE found:  37502.1924786\n"
     ]
    }
   ],
   "source": [
    "# Random Search with XGBoost\n",
    "\n",
    "# Create the parameter grid: gbm_param_grid \n",
    "gbm_param_grid = {\n",
    "    'n_estimators': [25],\n",
    "    'max_depth': range(2, 12)\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBRegressor(n_estimators=10)\n",
    "\n",
    "# Perform random search: grid_mse\n",
    "randomized_mse = RandomizedSearchCV(estimator=gbm,cv=4,n_iter=5,verbose=1,\n",
    "                                    param_distributions=gbm_param_grid,\n",
    "                                    scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit randomized_mse to the data\n",
    "randomized_mse.fit(X,y)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", randomized_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(randomized_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limits of Grid Search and Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search\n",
    "- Number of models you must build with every additional new parameter grows very quickly\n",
    "- Optimal if no. of hyperparameters and distinct values per hyperparameter is kept small\n",
    "- Time taken increases exponentially\n",
    "\n",
    "Random Search\n",
    "- Parameter space to explore can be massive \n",
    "- Randomly jumping throughout the space looking for a \"best\" result becomes a waiting game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap 4: Using XGBoost in pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of pipelines using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline Review  \n",
    "- Takes a list of named 2-tuples (name, pipeline_step) as input\n",
    "- Tuples can contain any arbitrary scikit-learn compatible estimator or transformer object\n",
    "- Pipeline implements fit/predict methods\n",
    "- Can be used as input estimator into methods like\n",
    "    - grid/randomized search approaches - for tuning hyperparameters\n",
    "    - cross_val_score - for efficient cross-validation and out of sample metric calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "names = [\"crime\",\"zone\",\"industry\",\"charles\",\"no\",\"rooms\",\"age\", \n",
    "         \"distance\",\"radial\",\"tax\",\"pupil\",\"aam\",\"lower\",\"med_price\"]\n",
    "\n",
    "data = pd.read_csv(\"datasets/boston.csv\",names=names,skiprows=1)\n",
    "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "\n",
    "rf_pipeline = Pipeline([(\"st_scaler\",StandardScaler()),\n",
    "                       (\"rf_model\",RandomForestRegressor())])\n",
    "\n",
    "scores = cross_val_score(rf_pipeline, X, y, cv=10,\n",
    "                         scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE: 4.30351262932\n"
     ]
    }
   ],
   "source": [
    "final_avg_rmse = np.mean(np.sqrt(np.abs(scores)))\n",
    "print(\"Final RMSE:\", final_avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- neg_mean_squared_error is scikit-learn's way of calculating the mean squared error in an API-compatible way.  \n",
    "- Negative mean squared errors don't exist as all squares must be positive when working with real numbers.\n",
    "- Thus we simply take the absolute value of the scores, take each of their square roots, and compute their mean to get root mean squared error across all 10 cross-validation folds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing  \n",
    "- Do the same preprocessing in two different ways\n",
    "- only one of them can be done within a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Approach - LabelEncoder and OneHotEncoder\n",
    "- LabelEncoder: Converts a categorical column of strings into integers\n",
    "- OneHotEncoder: Takes the column of integers and encodes them as dummy variables\n",
    "- Cannot be done within a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Approach - DictVectorizer\n",
    "- can accomplish both steps in one line of code\n",
    "- found in feature extraction sub-module\n",
    "- Traditionally used in text processing pipelines\n",
    "- Converts lists of feature mappings into vectors\n",
    "- Does not directly work with dataframes\n",
    "    - Using pandas dataframes we don't initially have these features in lists form\n",
    "    - Need to convert DataFrame into a list of dictionary entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 21 columns):\n",
      "MSSubClass      1460 non-null int64\n",
      "MSZoning        1460 non-null object\n",
      "LotFrontage     1201 non-null float64\n",
      "LotArea         1460 non-null int64\n",
      "Neighborhood    1460 non-null object\n",
      "BldgType        1460 non-null object\n",
      "HouseStyle      1460 non-null object\n",
      "OverallQual     1460 non-null int64\n",
      "OverallCond     1460 non-null int64\n",
      "YearBuilt       1460 non-null int64\n",
      "Remodeled       1460 non-null int64\n",
      "GrLivArea       1460 non-null int64\n",
      "BsmtFullBath    1460 non-null int64\n",
      "BsmtHalfBath    1460 non-null int64\n",
      "FullBath        1460 non-null int64\n",
      "HalfBath        1460 non-null int64\n",
      "BedroomAbvGr    1460 non-null int64\n",
      "Fireplaces      1460 non-null int64\n",
      "GarageArea      1460 non-null int64\n",
      "PavedDrive      1460 non-null object\n",
      "SalePrice       1460 non-null int64\n",
      "dtypes: float64(1), int64(15), object(5)\n",
      "memory usage: 239.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Exploratory data analysis \n",
    "# (of unprocessed Ames housing dataset)\n",
    "\n",
    "df = pd.read_csv('datasets/ames_unprocessed_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MSZoning Neighborhood BldgType HouseStyle PavedDrive\n",
      "0       RL      CollgCr     1Fam     2Story          Y\n",
      "1       RL      Veenker     1Fam     1Story          Y\n",
      "2       RL      CollgCr     1Fam     2Story          Y\n",
      "3       RL      Crawfor     1Fam     2Story          Y\n",
      "4       RL      NoRidge     1Fam     2Story          Y\n",
      "   MSZoning  Neighborhood  BldgType  HouseStyle  PavedDrive\n",
      "0         3             5         0           5           2\n",
      "1         3            24         0           2           2\n",
      "2         3             5         0           5           2\n",
      "3         3             6         0           5           2\n",
      "4         3            15         0           5           2\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical columns I: LabelEncoder\n",
    "\n",
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Fill missing values with 0\n",
    "df.LotFrontage = df.LotFrontage.fillna(0)\n",
    "\n",
    "# Create a boolean mask for categorical columns\n",
    "categorical_mask = (df.dtypes == 'object')\n",
    "\n",
    "# Get list of categorical column names\n",
    "categorical_columns = df.columns[categorical_mask].tolist()\n",
    "\n",
    "# Print the head of the categorical columns\n",
    "print(df[categorical_columns].head())\n",
    "\n",
    "# Create LabelEncoder object: le\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to categorical columns\n",
    "df[categorical_columns] = df[categorical_columns].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "# Print the head of the LabelEncoded categorical columns\n",
    "print(df[categorical_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00   6.00000000e+01   6.50000000e+01\n",
      "    8.45000000e+03   7.00000000e+00   5.00000000e+00   2.00300000e+03\n",
      "    0.00000000e+00   1.71000000e+03   1.00000000e+00   0.00000000e+00\n",
      "    2.00000000e+00   1.00000000e+00   3.00000000e+00   0.00000000e+00\n",
      "    5.48000000e+02   2.08500000e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00   2.00000000e+01   8.00000000e+01\n",
      "    9.60000000e+03   6.00000000e+00   8.00000000e+00   1.97600000e+03\n",
      "    0.00000000e+00   1.26200000e+03   0.00000000e+00   1.00000000e+00\n",
      "    2.00000000e+00   0.00000000e+00   3.00000000e+00   1.00000000e+00\n",
      "    4.60000000e+02   1.81500000e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00   6.00000000e+01   6.80000000e+01\n",
      "    1.12500000e+04   7.00000000e+00   5.00000000e+00   2.00100000e+03\n",
      "    1.00000000e+00   1.78600000e+03   1.00000000e+00   0.00000000e+00\n",
      "    2.00000000e+00   1.00000000e+00   3.00000000e+00   1.00000000e+00\n",
      "    6.08000000e+02   2.23500000e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00   7.00000000e+01   6.00000000e+01\n",
      "    9.55000000e+03   7.00000000e+00   5.00000000e+00   1.91500000e+03\n",
      "    1.00000000e+00   1.71700000e+03   1.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00   0.00000000e+00   3.00000000e+00   1.00000000e+00\n",
      "    6.42000000e+02   1.40000000e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00   6.00000000e+01   8.40000000e+01\n",
      "    1.42600000e+04   8.00000000e+00   5.00000000e+00   2.00000000e+03\n",
      "    0.00000000e+00   2.19800000e+03   1.00000000e+00   0.00000000e+00\n",
      "    2.00000000e+00   1.00000000e+00   4.00000000e+00   1.00000000e+00\n",
      "    8.36000000e+02   2.50000000e+05]]\n",
      "(1460, 21)\n",
      "(1460, 62)\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical columns II: OneHotEncoder\n",
    "\n",
    "# Import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create OneHotEncoder: ohe\n",
    "ohe = OneHotEncoder(categorical_features=categorical_mask,sparse=False)\n",
    "\n",
    "# Apply OneHotEncoder to categorical columns - output is no longer a dataframe: df_encoded\n",
    "df_encoded = ohe.fit_transform(df)\n",
    "\n",
    "# Print first 5 rows of the resulting dataset - again, this will no longer be a pandas dataframe\n",
    "print(df_encoded[:5, :])\n",
    "\n",
    "# Print the shape of the original DataFrame\n",
    "print(df.shape)\n",
    "\n",
    "# Print the shape of the transformed array\n",
    "print(df_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t3.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 5)\t2.0\n",
      "  (0, 6)\t548.0\n",
      "  (0, 7)\t1710.0\n",
      "  (0, 8)\t1.0\n",
      "  (0, 9)\t5.0\n",
      "  (0, 10)\t8450.0\n",
      "  (0, 11)\t65.0\n",
      "  (0, 12)\t60.0\n",
      "  (0, 13)\t3.0\n",
      "  (0, 14)\t5.0\n",
      "  (0, 15)\t5.0\n",
      "  (0, 16)\t7.0\n",
      "  (0, 17)\t2.0\n",
      "  (0, 19)\t208500.0\n",
      "  (0, 20)\t2003.0\n",
      "  (1, 0)\t3.0\n",
      "  (1, 3)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 5)\t2.0\n",
      "  (1, 6)\t460.0\n",
      "  (1, 7)\t1262.0\n",
      "  (1, 9)\t2.0\n",
      "  (1, 10)\t9600.0\n",
      "  :\t:\n",
      "  (3, 14)\t6.0\n",
      "  (3, 15)\t5.0\n",
      "  (3, 16)\t7.0\n",
      "  (3, 17)\t2.0\n",
      "  (3, 18)\t1.0\n",
      "  (3, 19)\t140000.0\n",
      "  (3, 20)\t1915.0\n",
      "  (4, 0)\t4.0\n",
      "  (4, 2)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (4, 5)\t2.0\n",
      "  (4, 6)\t836.0\n",
      "  (4, 7)\t2198.0\n",
      "  (4, 8)\t1.0\n",
      "  (4, 9)\t5.0\n",
      "  (4, 10)\t14260.0\n",
      "  (4, 11)\t84.0\n",
      "  (4, 12)\t60.0\n",
      "  (4, 13)\t3.0\n",
      "  (4, 14)\t15.0\n",
      "  (4, 15)\t5.0\n",
      "  (4, 16)\t8.0\n",
      "  (4, 17)\t2.0\n",
      "  (4, 19)\t250000.0\n",
      "  (4, 20)\t2000.0\n",
      "{'MSSubClass': 12, 'MSZoning': 13, 'LotFrontage': 11, 'LotArea': 10, 'Neighborhood': 14, 'BldgType': 1, 'HouseStyle': 9, 'OverallQual': 16, 'OverallCond': 15, 'YearBuilt': 20, 'Remodeled': 18, 'GrLivArea': 7, 'BsmtFullBath': 2, 'BsmtHalfBath': 3, 'FullBath': 5, 'HalfBath': 8, 'BedroomAbvGr': 0, 'Fireplaces': 4, 'GarageArea': 6, 'PavedDrive': 17, 'SalePrice': 19}\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical columns III: DictVectorizer\n",
    "\n",
    "# Import DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Convert df into a dictionary: df_dict\n",
    "df_dict = df.to_dict('records')\n",
    "\n",
    "# Create the DictVectorizer object: dv\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# Apply dv on df: df_encoded\n",
    "df_encoded = dv.fit_transform(df_dict)\n",
    "\n",
    "# Print the resulting first five rows\n",
    "print(df_encoded[:5,:])\n",
    "\n",
    "# Print the vocabulary\n",
    "print(dv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('ohe_onestep', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('xgb_model', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_ch...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing within a pipeline\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "# Fill LotFrontage missing values with 0\n",
    "X.LotFrontage = X.LotFrontage.fillna(0)\n",
    "\n",
    "# Setup the pipeline steps: steps\n",
    "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n",
    "         (\"xgb_model\", xgb.XGBRegressor())]\n",
    "\n",
    "# Create the pipeline: xgb_pipeline\n",
    "xgb_pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline\n",
    "xgb_pipeline.fit(X.to_dict('records'),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating XGBoost into pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have XGBoost in pipeline, use its scikit-learn API within a pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGB RMSE: 4.02719593323\n"
     ]
    }
   ],
   "source": [
    "# Scikit-Learn Pipeline Example With XGBoost\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "names = [\"crime\",\"zone\",\"industry\",\"charles\",\"no\",\"rooms\",\"age\", \n",
    "         \"distance\",\"radial\",\"tax\",\"pupil\",\"aam\",\"lower\",\"med_price\"]\n",
    "data = pd.read_csv(\"datasets/boston.csv\",names=names,skiprows=1)\n",
    "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "\n",
    "xgb_pipeline = Pipeline([(\"st_scaler\",StandardScaler()),\n",
    "                         (\"xgb_model\",xgb.XGBRegressor())])\n",
    "\n",
    "scores = cross_val_score(xgb_pipeline, X, y,cv=10,\n",
    "                         scoring=\"neg_mean_squared_error\")\n",
    "final_avg_rmse = np.mean(np.sqrt(np.abs(scores)))\n",
    "print(\"Final XGB RMSE:\", final_avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Components Introduced For Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn_pandas: (sklearn and pandas both not always work seamlessly)\n",
    "    - DataFrameMapper - Interoperability between pandas and scikit-learn\n",
    "    - CategoricalImputer - Allow for imputation of categorical variables before conversion to integers\n",
    "- sklearn.preprocessing:\n",
    "    - Imputer - Native imputation of numerical columns in scikit-learn\n",
    "- sklearn.pipeline:\n",
    "    - FeatureUnion - combine multiple pipelines of features into a single pipeline of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold RMSE:  30343.4865518\n"
     ]
    }
   ],
   "source": [
    "# Cross-validating your XGBoost model\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "# Fill LotFrontage missing values with 0\n",
    "X.LotFrontage = X.LotFrontage.fillna(0)\n",
    "\n",
    "# Setup the pipeline steps: steps\n",
    "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n",
    "         (\"xgb_model\", xgb.XGBRegressor(max_depth=2, objective=\"reg:linear\"))]\n",
    "\n",
    "# Create the pipeline: xgb_pipeline\n",
    "xgb_pipeline = Pipeline(steps)\n",
    "\n",
    "# Cross-validate the model\n",
    "cross_val_scores = cross_val_score(xgb_pipeline,X.to_dict('records'),y,cv=10,scoring='neg_mean_squared_error')\n",
    "\n",
    "# Print the 10-fold RMSE\n",
    "print(\"10-fold RMSE: \", np.mean(np.sqrt(np.abs(cross_val_scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kidney disease case study I: Categorical Imputer\n",
    "\n",
    "kidney_data = pd.read_csv('datasets/chronic_kidney_disease.csv',header=None,na_values='?')\n",
    "\n",
    "kidney_feature_names = ['age','bp','sg','al','su','bgr','bu','sc','sod',\n",
    "                        'pot','hemo','pcv','wc','rc','rbc','pc','pcc',\n",
    "                        'ba','htn','dm','cad','appet','pe','ane']\n",
    "kidney_target_name = ['class']\n",
    "df.columns = kidney_feature_names + kidney_target_name\n",
    "X, y = kidney_data.iloc[:,:-1], kidney_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn_pandas import CategoricalImputer\n",
    "\n",
    "# Check number of nulls in each feature column\n",
    "nulls_per_column = X.isnull().sum()\n",
    "print(nulls_per_column)\n",
    "\n",
    "# Create a boolean mask for categorical columns\n",
    "categorical_feature_mask = X.dtypes == object\n",
    "\n",
    "# Get list of categorical column names\n",
    "categorical_columns = X.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "# Get list of non-categorical column names\n",
    "non_categorical_columns = X.columns[~categorical_feature_mask].tolist()\n",
    "\n",
    "# Apply numeric imputer\n",
    "numeric_imputation_mapper = \\\n",
    "DataFrameMapper([([numeric_feature], Imputer(strategy=\"median\")) \\\n",
    "                 for numeric_feature in non_categorical_columns], \\\n",
    "                input_df=True,\n",
    "                df_out=True)\n",
    "\n",
    "# Apply categorical imputer\n",
    "categorical_imputation_mapper = \\\n",
    "DataFrameMapper([(category_feature, CategoricalImputer()) \\\n",
    "                 for category_feature in categorical_columns],\\\n",
    "                input_df=True,\n",
    "                df_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kidney disease case study II: Feature Union\n",
    "\n",
    "# Import FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Combine the numeric and categorical transformations\n",
    "numeric_categorical_union = \\\n",
    "FeatureUnion([(\"num_mapper\", numeric_imputation_mapper),\\\n",
    "              (\"cat_mapper\", categorical_imputation_mapper)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numeric_categorical_union' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-e43b2d896daa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Create full pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m pipeline = Pipeline([\n\u001b[1;32m----> 5\u001b[1;33m                      \u001b[1;33m(\u001b[0m\u001b[1;34m\"featureunion\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_categorical_union\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                      \u001b[1;33m(\u001b[0m\u001b[1;34m\"dictifier\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDictifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                      \u001b[1;33m(\u001b[0m\u001b[1;34m\"vectorizer\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDictVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numeric_categorical_union' is not defined"
     ]
    }
   ],
   "source": [
    "# Kidney disease case study III: Full pipeline\n",
    "\n",
    "# Create full pipeline\n",
    "pipeline = Pipeline([\n",
    "                     (\"featureunion\", numeric_categorical_union),\n",
    "                     (\"dictifier\", Dictifier()),\n",
    "                     (\"vectorizer\", DictVectorizer(sort=False)),\n",
    "                     (\"clf\", xgb.XGBClassifier(max_depth=3))\n",
    "                    ])\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(pipeline, X, y, scoring=\"roc_auc\", cv=3)\n",
    "\n",
    "# Print avg. AUC\n",
    "print(\"3-fold AUC: \", np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning XGBoost hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "Remember, in order to pass hyperparameters to the appropriate step, \n",
    "- you have to name the parameters in the dictionary with the name of the step being referenced \n",
    "- followed by 2 underscore signs and then the name of the hyperparameter you want to iterate over.  \n",
    "\n",
    "Since the xgboost step is called xgb_model, all of our hyperparameter keys will start with xgboost_model__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score='raise',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('st_scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('xgb_model', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_chil...       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'xgb_model__subsample': array([ 0.05,  0.1 ,  0.15,  0.2 ,  0.25,  0.3 ,  0.35,  0.4 ,  0.45,\n",
       "        0.5 ,  0.55,  0.6 ,  0.65,  0.7 ,  0.75,  0.8 ,  0.85,  0.9 ,  0.95]), 'xgb_model__max_depth': array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]), 'xgb_model__colsample_bytree': array([ 0.1 ,  0.15,  0.2 ,  0.25,  0.3 ,  0.35,  0.4 ,  0.45,  0.5 ,\n",
       "        0.55,  0.6 ,  0.65,  0.7 ,  0.75,  0.8 ,  0.85,  0.9 ,  0.95,  1.  ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuning XGBoost hyperparameters in a Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "names = [\"crime\",\"zone\",\"industry\",\"charles\",\"no\",\"rooms\",\"age\", \n",
    "         \"distance\",\"radial\",\"tax\",\"pupil\",\"aam\",\"lower\",\"med_price\"]\n",
    "data = pd.read_csv(\"datasets/boston.csv\",names=names,skiprows=1)\n",
    "X, y = data.iloc[:,:-1],data.iloc[:,-1]\n",
    "\n",
    "xgb_pipeline = Pipeline([(\"st_scaler\",StandardScaler()), \n",
    "                        (\"xgb_model\",xgb.XGBRegressor())])\n",
    "\n",
    "gbm_param_grid = {'xgb_model__subsample': np.arange(.05, 1, .05),\n",
    "                  'xgb_model__max_depth': np.arange(3,20,1),\n",
    "                  'xgb_model__colsample_bytree': np.arange(.1,1.05,.05) }\n",
    "\n",
    "randomized_neg_mse = \\\n",
    "RandomizedSearchCV (estimator=xgb_pipeline,n_iter=10,\n",
    "                    param_distributions=gbm_param_grid,\n",
    "                    scoring='neg_mean_squared_error', cv=4)\n",
    "\n",
    "randomized_neg_mse.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best rmse:  4.47691694445\n"
     ]
    }
   ],
   "source": [
    "# Tuning XGBoost hyperparameters in a Pipeline II\n",
    "\n",
    "print(\"Best rmse: \", np.sqrt(np.abs(randomized_neg_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:  Pipeline(memory=None,\n",
      "     steps=[('st_scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('xgb_model', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1.0000000000000004, gamma=0, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=11, min_child_weight=1, missing...0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=0.75000000000000011))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model: \", randomized_neg_mse.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing it all together\n",
    "\n",
    "# Create the parameter grid\n",
    "gbm_param_grid = {\n",
    "    'clf__learning_rate': np.arange(0.05, 1, 0.05),\n",
    "    'clf__n_estimators': np.arange(50, 200, 50),\n",
    "    'clf__max_depth': np.arange(3, 10, 1)}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "randomized_roc_auc = RandomizedSearchCV(estimator=pipeline,param_distributions=gbm_param_grid,scoring='roc_auc',cv=2,n_iter=2,verbose=1)\n",
    "\n",
    "# Fit the estimator\n",
    "randomized_roc_auc.fit(X,y)\n",
    "\n",
    "# Compute metrics\n",
    "print(randomized_roc_auc.best_score_)\n",
    "print(randomized_roc_auc.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What We Have Covered And You Have Learned\n",
    "\n",
    "- Using XGBoost for classification tasks\n",
    "- Using XGBoost for regression tasks\n",
    "- Tuning XGBoost's most important hyperparameters\n",
    "- Incorporating XGBoost into sklearn pipelines\n",
    "- Advanced functions that allow us to seamlessly work with Pandas DataFrames and scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What We Have NOT COVERED (And How You Can Proceed)\n",
    "\n",
    "- Using XGBoost for ranking/recommendation problems (Netflix/Amazon problem)\n",
    "    - can be done by modifying the loss function we use when constructing the model\n",
    "- Using more sophisticated hyperparameter tuning strategies for tuning XGBoost models (Bayesian Optimization)\n",
    "    - entire companies have been created just for using this method in tuning models.\n",
    "    - example: the company 'sigpot'\n",
    "- Using XGBoost as part of an ensemble of other models for regression/classification\n",
    "    - predictions we get from XGBoost model can be combined with other models\n",
    "    - very powerful additional way to squeeze the last bit of juice from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
